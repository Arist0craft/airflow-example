# Airflow Example repository
Репозиторий Airflow для "отработки" построения DAG'ов в локальной среде.

## Установка
### Требования
1. Должен быть установлен Python 3.11
2. Должен быть установлен [Docker](https://docs.docker.com/desktop/install/mac-install/)

### Установка и настройка среды
1. Клонируем проект
2. В проекте создаём виртуальное окружение
```bash
python -m venv ./.venv
```
3. Переключаемся на виртуальное окно в терминале. Некоторые IDE позволяют сделать это автоматически (VS Code, PyCharm)
* Linux/MacOS
```bash
source ./.venv/bin/activate
```
* Windows
```cmd
.venv\Scripts\activate.bat
```
4. Установить пакеты, необходимые для автоподсказок при разработке
```bash
pip install -r requirements.txt
```
## Разработка DAG'ов
Мы соблюдаем ряд правил для нормальной разработки, чтобы человек, читающий ваш код не вздёрнулся от визуального ужаса и последующих кошмаров.
* Соблюдаем нормальный нейминг переменных
* Пишем документацию к функциям внутри DAG'ов
* Пишем description для DAG'ов
* Группируем DAG'и в подпакеты, если они относятся к одному проекту, например, агрегат с детализацией по дням, неделям, месяцам
* Создаёшь или редактируешь DAG - создай ветку с названием задачи

### Сам процесс разработки:
Первый запуск потребует бОльшего количества времени для генерации всех файлов и сборки образа

1. Поднять Docker Compose. Локальный Airflow будет доступен по адресу https://localhost:8080
```bash
docker-compose up
```
2. Создать Git ветку с названием MDMA-..._example_dag_naming, где ... - номер задачи в таск-трекере
3. Написать DAG, аналогично уже существующим
4. Потушить Docker для экономии ресурсов ПК.
```bash
docker-compose down
```

### Примеры:
Создадим DAG dags/example/dag.py на ежедневную выгрузку данных из таблицы "продакшн" кластера ClickHouse и на загрузку данных в таблицу тестового кластера CH.

Прежде, чем приступать к работе, нам нужно добавить информацию о подключениях CH в специальный раздел админки Airflow - __Connections__. Чаще всего, вам не придётся заниматься подобным, ведь за безопасность всех кредов отвечает другой человек, но для общего понимания всё же стоит разобрать.

1. Заходим в Connections
2. Добавляем новое соединение на плюсик, пишем id латиницей и нижними подчёркиваниями, название должно быть уникальным.
3. Выбираем тип Postgres
4. Прописываем в поля креды для продакшена, host, login, password используем как есть, port - прописываем порт для native подключения
5. Сохраняем и повторяем для тестового клика похожую процедуру.

В DAG'е используются id соединений - clickhouse_prod и clickhouse_test соотвественно, вы можете назвать их по своему, но не забудьте поменять в файле DAG'а


А теперь к разбору самого DAG'а:
1. Создаём параметризацию DAG'а:  `get_dag_params()`. Параметризация нужна для запуска одного и того же DAG'а, допустим, за разные промежутки времени в ручную. Из параметров start_date и end_date - интервал начала выгрузки и конца. Параметры можно дополнительно обработать, например, убрать временную зону из питоновского _datetime_, т.к. функция ClickHouse toDate() не сможет корректно обработать временную зону.
2. Наш SQL скрипт так же параметризован, считаем файл в папке SQL и подставим параметры в шаблоны. Шаблоны пишем в формате `{template_param_name}` без лишних пробелов, иначе Python будет ругаться. Task'а __get_sql_str(query)__ отработала корректно, двигаемся дальше!
3. Далее проверяем для безопасной отработки, что таблица, в которую поместим данные, существует, если нет - создадим! С помощью Task'и __task_id='check_table'__.
4. Осталось немного, забрать данные из источника, в данном случае мы используем ClickHouseOperator с __task_id=get_data__. В чём же разница между Task'ой и Operator'ом ? Операторы были придуманы до того, как появилась обёртка `@task`, превращающая любую Python функцию в полнценную задачу Airflow. Многие интеграции (пакеты) до сих пор используют Операторы, ведь по факту Оператор +- обёртка над таской с некоторыми ограничениями и менее удобным флоу. В нашем случае ClickHouseOperator выполняет запрос, забирает данные и кладёт в промежуточное хранилище XCom
5. Мы получили данные, последний шаг - самый трудный в понимании, ведь до этого мы кидали данные между тасками в качестве аргументов Python функции, почему теперь код другой? В предыдущем пункте упоминалось, что Task != Operator и приходится изворачиваться, мы обращаемся к "контексту" DAG'а и забираем из XCom'а напрямую данные, которые дальше просто отправляем в итоговую таблицу.


### Добавление пакетов:
Если вам не хватает пакетов, можете добавить их в файл `requirements.txt` и пересобрать Docker образ, выполнив команду:
```bash
docker build -t airflow-example:latest .
```
